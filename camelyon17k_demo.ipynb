{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7FTPXzCYeaZ"
      },
      "source": [
        "Copyright 2024 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HkRnXLvDEhG"
      },
      "source": [
        "# Models for Camelyon17K\n",
        "\n",
        "This CoLAB shows how to load and run models on Camelyon17K. In particular, we have two sets of models:\n",
        "\n",
        "1. *Generative*: here the models generate synthetic images with and without tumours across different hospitals.\n",
        "2. *Classification*: here the models take an image of a potentially tumourous slide image and classify whether there are or are not tumours.\n",
        "\n",
        "The CoLAB is divided into two sections for these two use cases.\n",
        "\n",
        "We save our models using jax2tf for ease of use. Note that this CoLAB was *NOT* used for any results in the paper but is provided to (1) show sample results with our saved out models and (2) demonstrate how our pipeline operates.\n",
        "\n",
        "This code was run on a TPU so it is unclear how feasible the different parts will be to run on a CPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq8wR6UhMaKz"
      },
      "outputs": [],
      "source": [
        "# See instructions at https://github.com/google/jax#installation for how to install.\n",
        "# !pip install -U \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T04fYV8XDp4w"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "import jax\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaAUdCNzp2zr"
      },
      "outputs": [],
      "source": [
        "# @markdown Download the open source models.\n",
        "# @markdown Save them to `./open_source/`.\n",
        "\n",
        "# Path to open sourcing directory.\n",
        "base_path = './open_source/' # @param {type: 'string'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DgcVeOZjB4e"
      },
      "source": [
        "## Image Generation\n",
        "\n",
        "Here we show how to sample from two different generative models (trained on the full Camelyon dataset or the *most skewed* version) and also load samples generated by those models. Both models were trained with unlabelled data as well as labelled data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biiogreIkfOv"
      },
      "outputs": [],
      "source": [
        "# @title Sampling code\n",
        "# @markdown Note that you will need a GPU or TPU to run this in any amount of reasonable time.\n",
        "\n",
        "file_name =  'skewed100_gendata' # @param {type: 'string'} ['gendata', 'skewed100_gendata']\n",
        "\n",
        "if file_name == 'skewed100_gendata':\n",
        "  model_name = '44644773_3_skewed100_gendatamodel'\n",
        "else:\n",
        "  model_name = '51586976_1_genmodel'\n",
        "with tf.device('TPU'):\n",
        "  restored_model = tf.saved_model.load(f'{base_path}/histopathology/models/{model_name}/')\n",
        "\n",
        "all_images = []\n",
        "# We use these hospital ids from the WILDS dataset.\n",
        "# Hospital ids [1, 2] are OOD Val and Test.\n",
        "for hospital in [0, 3, 4]:\n",
        "  for label_id in [0, 1]:\n",
        "    one_hot_hospital = jax.nn.one_hot(hospital, 5)[None, :]\n",
        "    one_hot_label = jax.nn.one_hot(label_id, 2)[None, :]\n",
        "    res = restored_model(np.zeros(1,), one_hot_label, one_hot_hospital)\n",
        "    all_images.append(res[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTMRad7HKPT-"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(3, 2, figsize=(10, 10))\n",
        "\n",
        "for i in range(3):\n",
        "  for j in range(2):\n",
        "    ax[i][j].imshow(all_images[i * 2 + j])\n",
        "    ax[i][j].axis('off')\n",
        "    ax[i][j].set_title(f'Label: {j}, Center: {i}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PatnjEJ_NEso"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uco5VWoWDrCy"
      },
      "outputs": [],
      "source": [
        "# @title Load in a saved model and evaluate\n",
        "# @markdown This cell and the one below show how to load in the saved out models and run inference on them on the evaluation datasets.\n",
        "# @markdown We exported 4 models on histopathology: the baseline and our model conditioned on the hospital and tumor label (with color augmentation).\n",
        "# @markdown We export these two setups for the *most skewed* and *all data* setting.\n",
        "\n",
        "\n",
        "# @markdown Note that the following code gives only the results for one model: in the paper we report results across five runs.\n",
        "\n",
        "model_name = 'baseline' # @param {type: 'string'} ['ours_multiclass', 'baseline', 'skewed100_baseline', 'skewed100_ours_multiclass']\n",
        "device = 'CPU' # @param {type: 'string'} ['CPU', 'GPU', 'TPU']\n",
        "with tf.device(device):\n",
        "  restored_model = tf.saved_model.load(f'{base_path}/histopathology/models/{model_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPOJUx4wNKy_"
      },
      "outputs": [],
      "source": [
        "# @markdown Create a tfds version of the Camelyon17 dataset:\n",
        "# @markdown Follow the instructions in the [WILDS code](https://github.com/p-lambda/wilds/blob/main/wilds/datasets/camelyon17_dataset.py)\n",
        "# @markdown to download a the blob file which includes images and metadata.\n",
        "_CAMELYON_LOCATION = './camelyon17/' # @param\n",
        "TEST_CENTER = 2\n",
        "VAL_CENTER = 1\n",
        "\n",
        "# @markdown Here we load in the full dataset, but note we also created skewed versions in the paper\n",
        "# @markdown which are not shown here to demonstrate the robustness of our approach in these settings.\n",
        "\n",
        "def parse_function(filename, label, center):\n",
        "  image_string = tf.io.read_file(filename)\n",
        "  image_decoded = tf.image.decode_image(image_string)\n",
        "  image = tf.cast(image_decoded, tf.float32)\n",
        "  return {'image': image, 'label': label, 'center': center}\n",
        "\n",
        "def load_camelyon():\n",
        "  camelyon_path = os.path.join(_CAMELYON_LOCATION, 'metadata.csv')\n",
        "\n",
        "  metadata_df = pd.read_csv(camelyon_path, index_col=0,dtype={'patient': 'str'})\n",
        "  patches_location = f'{_CAMELYON_LOCATION}/patches/'\n",
        "  input_array = [\n",
        "      f'{patches_location}/patient_{patient}_node_{node}/patch_patient_{patient}_node_{node}_x_{x}_y_{y}.png'\n",
        "      for patient, node, x, y in\n",
        "      metadata_df.loc[:, ['patient', 'node', 'x_coord', 'y_coord']].itertuples(index=False, name=None)]\n",
        "  metadata_df['images'] = input_array\n",
        "\n",
        "  # Extract splits\n",
        "  split_dict = {\n",
        "            'train': 0,\n",
        "            'id_val': 1,\n",
        "            'test': 2,\n",
        "            'val': 3\n",
        "        }\n",
        "  val_center_mask = (metadata_df['center'] == VAL_CENTER)\n",
        "  test_center_mask = (metadata_df['center'] == TEST_CENTER)\n",
        "  metadata_df.loc[val_center_mask, 'split'] = split_dict['val']\n",
        "  metadata_df.loc[test_center_mask, 'split'] = split_dict['test']\n",
        "  return metadata_df\n",
        "\n",
        "camelyon_metadata = load_camelyon()\n",
        "\n",
        "def load_eval_dataset(batch_size, split='id_val'):\n",
        "  \"\"\"Load in the Camelyon eval dataset into a tfds structure.\"\"\"\n",
        "  if split == 'id_val':\n",
        "    split_id = 1\n",
        "  elif split == 'ood_test':\n",
        "    split_id = 2\n",
        "  elif split == 'ood_val':\n",
        "    split_id = 3\n",
        "  else:\n",
        "    raise ValueError(f'Unknown split: {split}')\n",
        "  eval_data = camelyon_metadata[camelyon_metadata['split'] == split_id]\n",
        "  files = eval_data['images'].values\n",
        "  labels = eval_data['tumor'].values\n",
        "  center = eval_data['center'].values\n",
        "  images = tf.constant(files)\n",
        "  labels = tf.constant(labels)\n",
        "  center = tf.constant(center)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((images, labels, center))\n",
        "  dataset = dataset.map(parse_function).batch(batch_size)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GnS7vf0mW4o"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "center = []\n",
        "true_labels = []\n",
        "\n",
        "\n",
        "for eval_dataset in ['id_val', 'ood_val', 'ood_test']:\n",
        "  print(f'Results for {eval_dataset}')\n",
        "  ds = load_eval_dataset(512, eval_dataset)\n",
        "  ds = tfds.as_numpy(ds)\n",
        "  for i, ds_item in enumerate(ds):\n",
        "    images = ds_item['image'].astype(np.float32) / 255.0\n",
        "    labels = ds_item['label']\n",
        "    centers = ds_item['center']\n",
        "\n",
        "    logits = restored_model(images)\n",
        "    predicted_label = np.argmax(logits, axis=-1)\n",
        "    predictions.append(predicted_label)\n",
        "    center.append(centers)\n",
        "    true_labels.append(labels)\n",
        "  print(\n",
        "      f'# samples: {np.concatenate(true_labels).shape[0]} in dataset'\n",
        "      f' {eval_dataset}'\n",
        "  )\n",
        "  print(\n",
        "      'Accuracy:'\n",
        "      f' {(np.concatenate(predictions) == np.concatenate(true_labels)).mean()}'\n",
        "  )\n",
        "\n",
        "  if eval_dataset == 'id_val':\n",
        "    centers = np.concatenate(center)\n",
        "    predictions = np.concatenate(predictions)\n",
        "    true_labels = np.concatenate(true_labels)\n",
        "    err_center = [\n",
        "        (predictions[centers == c] == true_labels[centers == c]).mean()\n",
        "        for c in np.unique(centers)\n",
        "    ]\n",
        "    print(f'Fairness GAP: {(max(err_center)) - min(err_center)}')\n",
        "  print('\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuax08JJaRIC"
      },
      "source": [
        "With the code above, you should get the following results. Note that these are results with a *single* model (in the paper we reported mean and standard deviation across five seeds):\n",
        "\n",
        "| model | checkpoint name | Training setup | ID_VAL | OOD_VAL | OOD_TEST | FAIRNESS_GAP |\n",
        "|--------|------|------|---------|---------|-----------|--------------|\n",
        "| Ours (Multi class) | `ours_multiclass` | All train | 98.0 | 94.2 | 94.8 | 0.006 |\n",
        "| Baseline | `baseline`  | All train | 92.4 | 85.1 | 62.4 | 0.041\n",
        "| Ours (Multi class) | `skewed100_ours_multiclass` | Most skewed | 96.0 | 92.9 | 94.2 | 0.023\n",
        "| Baseline | `skewed100_baseline`  | Most skewed | 75.7 | 88.6 | 64.3 | 0.464 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z7TuWS5xGTp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1erPHavpU5ntHNnV3j6rDTgxY5uexSPEn",
          "timestamp": 1705326055329
        },
        {
          "file_id": "1eUViTtvvoV2b1bXgUwzJ_-Ip8__n7umg",
          "timestamp": 1705323298445
        },
        {
          "file_id": "1VdphEI83Ioor-7HM7RD3cleZGSgsr8WN",
          "timestamp": 1691487304569
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
